from random import randint
import os
import re
import ast
from openai import OpenAI
from supplementary.config import *
from AGENTS.prompts_state_tracking import *
from datetime import datetime
import json
from itertools import combinations


class GAME:
    def __init__(self, N:int, BOARD:dict, SEED:int, LOG_DIAL:str, LOG_EVAL:str, LOG_GSM:str, BOARD_ID:int, ID:int):

        # parameters for naming convention
        self.run_start = datetime.now()
        self.id = ID
        self.prompt_type = "GSM, constrained action space, remaining rooms"

        self.N = N  # number of nodes
        self.other_user = {
            "BOT": "USER",
            "USER": "BOT",
        }  # structure for efficient indexing of the "other" user, when given the current user as key

        self.rooms = {
            "BOT": ["L", "E", "K", "B"],
            "USER": ["L", "E", "K", "B"],
        }  # list of available rooms (default: 4-nodes)

        # add other rooms depending on the number of nodes
        if self.N >= 5:
            self.rooms["BOT"].append("C")
            self.rooms["USER"].append("C")
        if self.N == 6:
            self.rooms["BOT"].append("A")
            self.rooms["USER"].append("A")

        # Logging files
        self.logging_dialogues = LOG_DIAL  # logging file containing all dialogues
        self.logging_GSM = LOG_GSM  # logging file containing all ground state manager outputs
        self.logging_eval = LOG_EVAL  # logging file containing all evaluation info

        # Graph contents - read from json outside of class
        self.boards = {
            "BOT": BOARD["BOT"],
            "USER": BOARD["USER"],
        }  # the boards given to the players
        self.solutions = {
            "BOT": [],
            "USER": [],
            "OPTIMAL": BOARD["OPTIMAL"],
        }  # storing the produced solutions for evaluation; OPTIMAL is the path that returns the most joint coins
        self.BOARD_ID = BOARD_ID

        # Flags
        self.playing = True  # True = the game is ongoing

        # DATA STRUCTURES
        self.actions_history = {
            "BOT": [],
            "USER": [],
        }  # list of  not used in this version
        self.agreements_history = {"BOT": [], "USER": []}  # might not be used, TBD
        self.end = {
            "BOT": False,
            "USER": False,
        }  # dict for storing whether an "end" actioin was generated by each

        # Agent params
        self.seed = SEED
        self.model = "gpt-4o-2024-08-06"
        self.bot_params = self.get_params("BOT")
        self.user_params = self.get_params("USER")

        # Players
        self.bot = BotInstance(
            BASE_PROMPT=GHOST_prompt(self.bot_params, self.N),
            MODEL=self.model,
            SEED=self.seed,
            MAXTOKENS=1200,
            BOARD=BOARD["BOT"],
        )  # bot agent

        self.user_proxy = BotInstance(
            BASE_PROMPT=USER_LIGHT_prompt(self.user_params, self.N),
            MODEL=self.model,
            SEED=self.seed,
            MAXTOKENS=1200,
            BOARD=BOARD["USER"],
        )  # user agent

        # Ground State Manager (GSM) - extracts information from message
        self.MANAGER = GroundStateManager(
            BASE_PROMPT=get_current_ws(self.N),
            MODEL=self.model,
            SEED=self.seed,
            MAXTOKENS=600,
        )

        self.PLAYERS = {"BOT":self.bot, "USER":self.user_proxy}

        # Eval flags:
        # identical - are the two agents' solutions identical?
        # adequate - is the solution of proper length? (may not be optimal)
        # optimal - is the given solution optimal?
        # empty-{bot|user} - is the {bot|user}'s submission empty
        self.results = {
            "IDENTICAL": False,
            "ADEQUATE": False,
            "OPTIMAL": False,
            "EMPTY-bot": False,
            "EMPTY-user": False,
            "SCORE": 0,
            "FINAL-IDENTICAL":{"BOT":False, "USER":False}
        }

    def get_params(self, entity): 
        ''' A function for unpacking the parameters from default boards to be passed to the respective agent.
        
        :param entity: str; BOT or USER
        :return params: dict
        '''

        unique_nodes = set(node for pair in self.boards[entity] for node in pair[:2])
        pairs = combinations(unique_nodes, 2) # Generate all possible pairs using combinations

        # Create dictionary with keys like "LB", "LE", etc., and lookup values in entity data
        params = {
            f"{x}{y}": next(
                (v for (p1, p2, v) in self.boards[entity] if {p1, p2} == {x, y}), None
            )
            for x, y in pairs
        }
        return params
    
    def get_score(self):
        '''The function for calculating the score of the (identical) path the players agreed upon by using their given boards.'''

        score = 0
        path = self.solutions["BOT"] # the solution is identical 
        pairs = [(path[i], path[i+1]) for i in range(len(path)-1)]

        sum_board = [(a, b, el1 + el2) for [a, b, el1] in self.boards["BOT"] for [a2, b2, el2] in self.boards["USER"] if a == a2 and b == b2]

        for pair in pairs:
            score += [value[2] for value in sum_board if (pair[0] == value[0] and pair[1] == value[1]) or (pair[0] == value[1] and pair[1] == value[0])][0]

        self.results["SCORE"] = score
    
    def solution_verification(self):
        '''A function for evaluating the models' performance - checks if the generated solutions are:
            - identical
            - adequate
            - optimal
            - empty
        '''
        if len(self.solutions["BOT"]) == 0:
            self.results["EMPTY-bot"] = True
        if len(self.solutions["USER"]) == 0:
            self.results["EMPTY-user"] = True

         # if both players submit a solution (i.e. no empty list in the values)
        if all(self.solutions[key] for key in self.solutions):
            if self.solutions["BOT"] == self.solutions["USER"]:  # if both key dictionaries are the same
                self.results["IDENTICAL"] = True # set identical to true
                self.get_score()
                if len(self.solutions['BOT']) == (self.N+1):
                    self.results['ADEQUATE'] = True

                if self.results["SCORE"] == self.solutions["OPTIMAL"][-1]:
                    # if the calculated score is the same as the best achievable path
                    self.results["OPTIMAL"] = True

    def log(self, MODE="dialogue", MSG="Default", ROLE="BOT", SUMMARY=None):
        """Logging function;

        :param  MODE: str; default: dialogue; distinguishes the kind of
        :param MSG: str; the message being logged, only needed for "dialogue" MODE
        :param ROLE: str; the message sender; options: BOT, USER, GSM
        :param SUMMARY: list of len 6; experiment instance metadata -
            [
                prompt type,
                start time / date,
                model,
                seed,
                board dict (keys: "BOT", 'USER'),
                optimal path(s)
            ]
        """
        if MODE == "dialogue":
            if SUMMARY == None:
                if ROLE == "GSM":  # GSM
                    with open(self.logging_GSM, "a") as log_file:
                        log_file.write(
                            f"[INPUT]:\t{self.MANAGER.previous_input[1:]}\n[OUTPUT]:\t{self.MANAGER.previous_message}\n\n"
                        )
                else:
                    with open(self.logging_dialogues, "a") as log_file:
                        log_file.write(f"[{ROLE}]:\n\t\t\t{MSG}\n")
                    if ROLE.endswith("-input"):
                        print(f"[{ROLE}]:\n\t{MSG}\n\n")
                    else:
                        print(f"[{ROLE}-output]: \n\t{MSG}\n\n------------------------------------------------\n")
            else:
                print(
                    f"""
                ------------------------------------------------
                                BATCH START {self.id}
                ------------------------------------------------
                Prompt type:\t{SUMMARY[0]}
                Exp start:\t{SUMMARY[1]}
                Model:\t{SUMMARY[2]}
                Seed:\t{SUMMARY[3]}
                Board ID:\t{self.BOARD_ID}
                Boards: 
                    \tBOT:\t{SUMMARY[4]["BOT"]}
                    \tUSER:\t{SUMMARY[4]['USER']}
                    \tOPTIMAL:\t{SUMMARY[5]["OPTIMAL"]}
                ------------------------------------------------\n"""
                )

                with open(self.logging_dialogues, "a") as log_file:
                    log_file.write(
                        f"""
                ------------------------------------------------                   
                                BATCH START {self.id}
                ------------------------------------------------
                Prompt type:\t{SUMMARY[0]}
                Exp start:\t{SUMMARY[1]}
                Model:\t{SUMMARY[2]}
                Seed:\t{SUMMARY[3]}
                Board ID:\t{self.BOARD_ID}
                Boards: \t\tBOT:\t{SUMMARY[4]["BOT"]}
                        \t\tUSER:\t{SUMMARY[4]['USER']}
                        \t\tOPTIMAL:\t{SUMMARY[5]["OPTIMAL"]}
                ------------------------------------------------\n"""
                    )

                with open(self.logging_GSM, "a") as log_file:
                    log_file.write(
                        f"""
                ------------------------------------------------                   
                                BATCH START {self.id}
                ------------------------------------------------
                Prompt type:\t{SUMMARY[0]}
                Exp start:\t{SUMMARY[1]}
                Model:\t{SUMMARY[2]}
                Seed:\t{SUMMARY[3]}
                Board ID:\t{self.BOARD_ID}
                Boards: \t\tBOT:\t{SUMMARY[4]["BOT"]}
                        \t\tUSER:\t{SUMMARY[4]['USER']}
                        \t\tOPTIMAL:\t{SUMMARY[5]["OPTIMAL"]}
                ------------------------------------------------\n"""
                    )

        elif MODE == "eval":
            with open(self.logging_eval, "a") as log_file:
                log_file.write(
                    f"""
        ------------------------------------------------
                        EVALUATION BREAKDOWN {self.id}
        ------------------------------------------------
                               BASICS
        ------------------------------------------------                       
        Experiment start:\t{self.run_start}
        Prompt type:\t{self.prompt_type}
        Model:\t{self.model}
        Seed:\t{self.seed}
        Board ID:\t{self.BOARD_ID}
        Starting boards:
                \t\tBOT:\t{self.boards["BOT"]}
                \t\tUSER:\t{self.boards['USER']}
        ------------------------------------------------
                        FINAL PATHS
        ------------------------------------------------
        BOT:\t{self.solutions["BOT"]}
        USER:\t{self.solutions['USER']}
        OPTIMAL:\t{self.solutions["OPTIMAL"]}
        ------------------------------------------------
                        EVALUATION RESULTS
        ------------------------------------------------
        \tScore:\t{self.results["SCORE"]}
        \tIdentical:\t{self.results["IDENTICAL"]}
        \tOptimal:\t{self.results["OPTIMAL"]}
        \tAdequate:\t{self.results["ADEQUATE"]}
        \tEmpty-bot:\t{self.results["EMPTY-bot"]}
        \tEmpty-user:\t{self.results["EMPTY-user"]}
        \tVisited=final-BOT:\t{self.results["FINAL-IDENTICAL"]["BOT"]}
        \tVisited=final-USER:\t{self.results["FINAL-IDENTICAL"]["USER"]}
        ------------------------------------------------
"""
                )
        elif MODE == "eval-terminated":
            with open(self.logging_eval, "a") as log_file:
                log_file.write(
                    f"""
        ------------------------------------------------
                        EVALUATION BREAKDOWN {self.id}
        ------------------------------------------------
                               BASICS
        ------------------------------------------------                       
        Experiment start:\t{self.run_start}
        Prompt type:\t{self.prompt_type}
        Model:\t{self.model}
        Seed:\t{self.seed}
        Board ID:\t{self.BOARD_ID}
        Starting boards:
                \t\tBOT:\t{self.boards["BOT"]}
                \t\tUSER:\t{self.boards['USER']}
        ------------------------------------------------
                    FINAL PATHS -- TERMINATED
        ------------------------------------------------
        BOT:\t{self.solutions["BOT"]}
        USER:\t{self.solutions['USER']}
        OPTIMAL:\t{self.solutions["OPTIMAL"]}
        ------------------------------------------------"""
                )

    def parse_message(self,MESSAGE):
            # Dictionary to store flags and content
        result = {}

        # regex to match the pattern [FLAG] followed by content
        # capture everything after a flag until the next flag or the end of the string

        try:
            pattern = r'\[([^\]]+)\]:(.*?)(?=\[\w+\]|$)'
            matches = re.findall(pattern, MESSAGE, flags=re.DOTALL)

            if not matches:  # If matches is empty, raise an exception to trigger the except block        
                raise Exception("No matches found with initial pattern")

            for flag, content in matches:
                result[flag.strip()] = content.strip()

        except:
            pattern = r'\[([^\]]+)\](.*?)(?=\[\w+\]|$)'
            matches = re.findall(pattern, MESSAGE, flags=re.DOTALL)

            for flag, content in matches:
                result[flag.strip()] = content.strip()

        return result

    def parse_actions(self, actions, ROLE="BOT"):
        
        list_of_actions = re.findall(
            r"\w+\-*\w*\(.*?\)", actions
        )  # separates the generated actions into a list
        path_pattern = r"\((.*?)\)"
        for action in list_of_actions:
            action_contents = re.findall(path_pattern, action)[
                0
            ]  # str, just the param, e.g. "['C', 'K']" or "['A', 'B', 'C', 'D', 'E']" or "K"
            if action.startswith("end"):  # end action

                FINAL_PATH = ast.literal_eval(action_contents)
                self.solutions[ROLE] = FINAL_PATH
                self.end[ROLE] = True
                if FINAL_PATH == self.PLAYERS[ROLE].visited:
                    self.results["FINAL-IDENTICAL"][ROLE] = True

            elif action.startswith("ask") or action.startswith("inform"):
                # add to actions_history
                self.actions_history[ROLE].append(action)

            elif (
                action.startswith("reject")
                or action.startswith("visit")
                or action.startswith("agree")
            ):

                if (
                    action not in self.agreements_history[ROLE]
                ):  # one suggestion and one final agreement can only be done once
                    # add the original action (same for both agents)

                    if action.startswith("visit"):
                        # update the list of rooms to exclude the room that has been labeled as "visited"
                        index_of_visited = self.rooms[ROLE].index(
                            re.search(r"[a-zA-Z]", ast.literal_eval(action_contents))
                            .group()
                            .upper()
                        )  # eliminate the quotation marks
                        self.rooms[ROLE].pop(index_of_visited)
                        self.PLAYERS[ROLE].visited.append(ast.literal_eval(action_contents))

                    self.agreements_history[ROLE].append(action)

    def run(self, start, TURNS):
        
        # logging the basics into the dialogue file 
        self.user_proxy.update_message_history(start)

        while self.playing:
            # terminate the program in case the agents get stuck in a loop
            TURNS -= 1
            if TURNS == 0:
                break

            if self.end["USER"] and self.end["BOT"]:
                self.solution_verification()
                self.playing = False
                break

            #################### USER BLOCK ####################
            user_message = (
                self.user_proxy.get_inference()
            )  # messages generated by the user proxy
            self.log(MSG=user_message, ROLE="USER")  # log user message
            user_message_PARSED = self.parse_message(
                user_message
            )  # separate [Thought] [Action] and [Message]

            # GROUND STATE MANAGER BLOCK: update the BOT's "other state" (after USER's turn)
            try:
                gsm_output_raw = self.MANAGER.get_inference(user_message_PARSED["Message"], self.bot.other_user_WS, self.user_proxy.visited[-1], "LIGHT") # pass user's last "visited" node bc it's the user's message
                gsm_output_parsed = self.parse_message(gsm_output_raw)
                self.log(ROLE="GSM")
                NWS = re.sub(
                    r"[^a-zA-Z0-9\s\[\]\(\)\"',]", "", gsm_output_parsed["NWS"].strip()
                )  # NWS = new world state

                self.bot.other_user_WS += ast.literal_eval(
                    NWS
                )  # update in bot's history
                if len(ast.literal_eval(NWS)) > 0:
                    self.bot.update_total_board(ast.literal_eval(NWS))
                    
            except:  # formatting issue
                pass

            try: # upadate actions after GSM (take old Loc)
                self.parse_actions(user_message_PARSED["Action"], "USER")
            except:
                pass

            try:
                new_string = f"[World-state-own]: {self.boards['BOT']}\n[World-state-user]: {self.bot.other_user_WS}\n[Visited]: {self.bot.visited}\n[Remaining]: {self.rooms["BOT"]}\n[Observation]: {user_message_PARSED['Message']}"

            except:  # if there is an error is user message formatting (cannot access [user_message_PARSED['Message']])
                new_string = f"[World-state-own]: {self.boards['BOT']}\n[World-state-user]: {self.bot.other_user_WS}\n[Visited]: {self.bot.visited}\n[Remaining]: {self.rooms["BOT"]}\n[Observation]: <USER MESSAGE IN WRONG FORMAT>"

            print(f'INPUT - BOT: {new_string}\n')
            self.log(MSG=new_string, ROLE="BOT-input")
            self.bot.update_message_history(
                new_string
            )  # add new input (based on the USER's output) to BOT's msg history

            if self.end["USER"] and self.end["BOT"]:
                self.solution_verification()
                self.playing = False
                break

            #################### BOT BLOCK ####################
            else:
                bot_message = self.bot.get_inference()
                self.log(MSG=bot_message, ROLE="BOT")  # log bot message
                bot_message_PARSED = self.parse_message(
                    bot_message
                )  # extract bot actions


                # GROUND STATE MANAGER block: update the state based on message and old state
                try:
                    gsm_output_raw = self.MANAGER.get_inference(bot_message_PARSED["Message"], self.user_proxy.other_user_WS, self.bot.visited[-1], "GHOST")
                    gsm_output_parsed = self.parse_message(gsm_output_raw)
                    self.log(ROLE="GSM")
                    NWS = re.sub(
                        r"[^a-zA-Z0-9\s\[\]\(\)\"',]",
                        "",
                        gsm_output_parsed["NWS"].strip(),
                    )
                    self.user_proxy.other_user_WS += ast.literal_eval(
                        NWS
                    )  # update in user proxy's history
                    if len(ast.literal_eval(NWS)) > 0:
                        self.user_proxy.update_total_board(
                            ast.literal_eval(NWS)
                        )  # update user proxy's total_board
            
                    # else continue without updating
                except:  # formatting issue in parsing GSM's message OR extracting NWS
                    pass

                try:
                    self.parse_actions(bot_message_PARSED["Action"], "BOT")
                except:
                    pass
                
                try:
                    new_string = f"[World-state-own]: {self.boards['USER']}\n[World-state-user]: {self.user_proxy.other_user_WS}\n[Visited]: {self.user_proxy.visited}\n[Remaining]: {self.rooms["USER"]}\n[Observation]: {bot_message_PARSED['Message']}"
                except:
                    new_string = f"[World-state-own]: {self.boards['USER']}\n[World-state-user]: {self.user_proxy.other_user_WS}\n[Visited]: {self.user_proxy.visited}\n[Remaining]: {self.rooms["USER"]}\n[Observation]: <USER MESSAGE IN WRONG FORMAT>"

                self.user_proxy.update_message_history(new_string)
                print(f'INPUT - USER: {new_string}\n')
                self.log(MSG=new_string, ROLE="USER-input")
                if self.end["USER"] and self.end["BOT"]:
                    self.solution_verification()
                    self.playing = False
                    break

        # Log the eval results to a separate eval file
        if not (self.end["USER"] and self.end["BOT"]):
            self.log(MODE='eval-terminated')
        else:
            self.log(MODE="eval")

class BotInstance:
     
    def __init__(self, BASE_PROMPT: str, MODEL: str, SEED: int, MAXTOKENS: int, BOARD: list):
        self.msg_history = [{"role":"system", "content":BASE_PROMPT}]
        self.model = MODEL #"gpt-4o-2024-08-06"
        self.seed = SEED
        self.recent_message = None
        self.MAXTOKENS = MAXTOKENS
        self.other_user_WS = []
        self.visited = ["L"]

    def inference(self, MSGS): 
        client = OpenAI(api_key=OPENAI_API_KEY)
    # seed to reproduce, should be put in the paper so the number should be normal lol
        completion = client.chat.completions.create(
        model=self.model,
        messages=MSGS,
        max_tokens=self.MAXTOKENS,
        temperature=1,
        seed=self.seed
        )
        output = completion.choices[0].message.content        
        return output

    def get_inference(self):

        raw_output = self.inference(MSGS=self.msg_history)
        self.msg_history.append({"role":"assistant", "content":raw_output})
        self.recent_message = raw_output
        return raw_output
    
    def update_message_history(self,new_message):
        self.msg_history.append({"role":"user", "content":new_message})
                
class GroundStateManager:
    def __init__(self, BASE_PROMPT: str, MODEL: str, SEED: int, MAXTOKENS: int):
        """
        A class for the LLM-based Ground State Manager (GSM), whose main job is to extract new information about the graph of "the other player".

        :param BASE_PROMPT: str; the system prompt - task explanation + example.
        :param MODEL: str; the OpenAI model to be called
        :param SEED: int;
        :param MAXTOKENS:int;
        """
        self.msg_history = [{"role": "system", "content": BASE_PROMPT}]
        self.model = MODEL  # "gpt-4o-2024-08-06"
        self.seed = SEED
        self.MAXTOKENS = MAXTOKENS
        self.previous_input = None  # the last recorded input str; for logging purposes

    def inference(self, input: list):
        """A function that calls the OpenAI API using the previously set parameters

        :return output: str; model output
        """
        client = OpenAI(api_key=OPENAI_API_KEY)
        completion = client.chat.completions.create(
            model=self.model,
            messages=input,
            max_tokens=self.MAXTOKENS,
            temperature=1,
            seed=self.seed,
        )
        output = completion.choices[0].message.content
        return output

    def make_input(self, message: str, old_ws: list, loc: str, world: str):
        """A function that generates the input to be passed to the LLM. Does not store previous messages, just appends the newest inquiry to the base prompt.
        :param message: str;
        :param old_ws: list; "old world state" - the parts of the other player's graph that have been found out
        :return input: list(dict); the input list of messages to be passed to the LLM
        """
        input_string = f"[Message]: {message}\n[OWS]: {old_ws}\n[Loc]: {loc}\n[World]:{world}"
        formatted_input = [{"role": "user", "content": input_string}]
        input = self.msg_history + formatted_input
        return input

    def get_inference(self, MESSAGE: str, OWS: list, LOC: str, WORLD: str):
        """A function that organizes the LLM API call and stores data where necessary.

        :param MESSAGE: str;
        :param OWS: list; "old world state", a.k.a. the parts of the other player's graph that have been found out

        :return raw_output: str; the complete output of the LLM. format: [Thought]: ... \n [NWS]: ...\n
        """
        input = self.make_input(MESSAGE, OWS, LOC, WORLD)
        raw_output = self.inference(input)
        self.previous_input = input
        self.previous_message = raw_output

        return raw_output
    

def main():

    NODES = 6
    BOARDS_PATH = f"boards_{NODES}.json"
    prompt_type = ""
    n = 25
    version = "full-v10-visited-remaining-fix"
    setup = f"{NODES}nodes"

    for seed in [1011, 143, 9999, 8060]: # 1011 8060 9999
    # seed = 1011 # 9999 1234 8060
        run_start = datetime.now()
        path = f"logs/{version}/{setup}"
        if not os.path.exists(path):
            os.makedirs(path)
        
        logging_didalogues = f"{path}/{seed}-{run_start}-dialogues.txt"
        logging_eval = f"{path}/{seed}-{run_start}-eval.txt"
        logging_GSM = f"{path}/{seed}-{run_start}-GSM.txt"

        with open(BOARDS_PATH, "r") as file:
            boards = json.load(file)
        
        for i in range(n):
        # send a random board from json file
            ID = f"{seed}-{i}"
            board_index = str(randint(1,6))
            board = boards[board_index]
            game = GAME(NODES, board, seed, logging_didalogues, logging_eval, logging_GSM, board_index, ID) # start a game instance
            start = f"[World-state-own]: {game.boards["USER"]}\n[World-state-user]: {game.user_proxy.other_user_WS}\n[Visited]: {game.user_proxy.visited}\n[Remaining]: {game.rooms["USER"]}\n[Observation]: <START>"
            game.log(
            SUMMARY=[
                game.prompt_type,
                game.run_start,
                game.model,
                game.seed,
                game.boards,
                game.solutions,
            ]
        )
            game.log(MSG=start, ROLE="USER-input")
            game.run(start=start, TURNS=16)

if __name__ == "__main__":
    main()