from random import randint
import re
import ast
import os
from openai import OpenAI
from supplementary.config import *
from AGENTS.prompts_coin_tracking import *
from datetime import datetime
import json
from itertools import combinations


class GAME:

    def __init__(self, N:int, BOARD:dict, SEED:int, LOG_DIAL:str, LOG_EVAL:str, LOG_GSM:str, BOARD_ID:int, ID:int):
        ''' The GAME-governing class
            
            :param N: int; number of nodes
            :param BOARD: dict; dict contianing the boards for both agents, indexed under roles (BOT, USER).
            :param SEED: int; batch marker; same for both agents
            :param LOG_DIAL: str; path to dialogue log file
            :param LOG_EVAL: str; path to eval log file
            :param LOG_GSM: str;  path to GroundStateManager (GSM) log file
            :param BOARD_ID: int; the ID of the board (used for logging)
            :param ID: int; the ID of the game within the batch (used for logging)
            '''

        # parameters for naming convention
        self.run_start = datetime.now()
        self.id = ID
        self.prompt_type = ""

        self.N = N # number of nodes
        self.other_user = {"BOT":"USER", "USER":"BOT"} # structure for efficient indexing of the "other" user, when given the current user as key

        self.rooms = {"BOT": ["L", "E", "K", "B"], "USER": ["L", "E", "K", "B"]} # list of available rooms (default: 4-nodes)
        
        # add other rooms depending on the number of nodes
        if self.N >= 5:
            self.rooms["BOT"].append("C")
            self.rooms["USER"].append("C")
        if self.N == 6:
            self.rooms["BOT"].append("A")
            self.rooms["USER"].append("A")

        # Logging files
        self.logging_dialogues = LOG_DIAL # logging file containing all dialogues
        self.logging_GSM = LOG_GSM # logging file containing all ground state manager outputs
        self.logging_eval = LOG_EVAL # logging file containing all evaluation info

         # Graph contents - read from json outside of class
        self.boards = {"BOT":BOARD["BOT"], "USER":BOARD["USER"]}  # the boards given to the players
        self.solutions = {"BOT":[], "USER":[], "OPTIMAL":BOARD["OPTIMAL"]} # storing the produced solutions for evaluation; OPTIMAL is the path that returns the most joint coins
        self.BOARD_ID = BOARD_ID

        # Flags
        self.playing = True # True = the game is ongoing

        # DATA STRUCTURES
        self.actions_history = {"BOT":[], "USER":[]} #list of  not used in this version
        self.end = {"BOT":False, "USER":False} # dict for storing whether an "end" actioin was generated by each   
        
        # Agent params
        self.seed = SEED
        self.model = "gpt-4o-2024-08-06"
        self.bot_params = self.get_params("BOT")
        self.user_params = self.get_params("USER")

        # Players
        self.bot = BotInstance(BASE_PROMPT=GHOST_prompt(self.bot_params, self.N), MODEL=self.model, SEED=self.seed, MAXTOKENS=1200, BOARD=BOARD["BOT"]) # bot agent
        
        self.user_proxy = BotInstance(BASE_PROMPT=USER_LIGHT_prompt(self.user_params, self.N), MODEL=self.model, SEED=self.seed, MAXTOKENS=1200, BOARD=BOARD["USER"]) # user agent

        # Ground State Manager (GSM) - extracts information from message
        self.MANAGER = GroundStateManager(BASE_PROMPT=get_current_ws(self.N), MODEL=self.model, SEED=self.seed, MAXTOKENS=600)
        
        # Eval flags:
            # identical - are the two agents' solutions identical?
            # adequate - is the solution of proper length? (may not be optimal)
            # optimal - is the given solution optimal?
            # empty-{bot|user} - is the {bot|user}'s submission empty
        self.results = {"IDENTICAL":False, "ADEQUATE":False, "OPTIMAL":False, "EMPTY-bot":False, "EMPTY-user":False, "SCORE":0}

    def get_params(self, player): 
        ''' A function for unpacking the parameters from default boards to be passed to the respective agent.
        
        :param player: str; BOT or USER
        :return params: dict
        '''

        unique_nodes = set(node for pair in self.boards[player] for node in pair[:2])
        pairs = combinations(unique_nodes, 2) # Generate all possible pairs using combinations

        # Create dictionary with keys like "LB", "LE", etc., and lookup values in player data
        params = {
            f"{x}{y}": next(
                (v for (p1, p2, v) in self.boards[player] if {p1, p2} == {x, y}), None
            )
            for x, y in pairs
        }
        return params
    
    def get_score(self):
        '''The function for calculating the score of the (identical) path the players agreed upon by using their given boards.'''

        score = 0
        path = self.solutions["BOT"] # the solution is identical 
        pairs = [(path[i], path[i+1]) for i in range(len(path)-1)]

        sum_board = [(a, b, el1 + el2) for [a, b, el1] in self.boards["BOT"] for [a2, b2, el2] in self.boards["USER"] if a == a2 and b == b2]

        for pair in pairs:
            score += [value[2] for value in sum_board if (pair[0] == value[0] and pair[1] == value[1]) or (pair[0] == value[1] and pair[1] == value[0])][0]

        self.results["SCORE"] = score
    
    def solution_verification(self):
        '''A function for evaluating the models' performance - checks if the generated solutions are:
            - identical
            - adequate
            - optimal
            - empty
        '''
        # if there is an empty list in the values, determine which one
        if len(self.solutions["BOT"]) == 0:
            self.results["EMPTY-bot"] = True
        if len(self.solutions["USER"]) == 0:
            self.results["EMPTY-user"] = True

         # if both players submit a solution (i.e. no empty list in the values)
        if all(self.solutions[key] for key in self.solutions):
            if self.solutions["BOT"] == self.solutions["USER"]:  # if both key dictionaries are the same
                self.results["IDENTICAL"] = True # set identical to true
                self.get_score()
                if len(self.solutions['BOT']) == (self.N+1):
                    self.results['ADEQUATE'] = True

                if self.results["SCORE"] == self.solutions["OPTIMAL"][-1]:
                    # if the calculated score is the same as the best achievable path
                    self.results["OPTIMAL"] = True

    def log(self, MODE="dialogue", MSG="Default", ROLE="BOT", SUMMARY=None):
        """Logging function;

        :param  MODE: str; default: dialogue; distinguishes the kind of
        :param MSG: str; the message being logged, only needed for "dialogue" MODE
        :param ROLE: str; the message sender; options: BOT, USER, GSM
        :param SUMMARY: list of len 6; experiment instance metadata -
            [
                prompt type,
                start time / date,
                model,
                seed,
                board dict (keys: "BOT", 'USER'),
                optimal path(s)
            ]
        """
        if MODE == "dialogue":
            if SUMMARY == None:
                if ROLE == "GSM":  # GSM
                    with open(self.logging_GSM, "a") as log_file:
                        log_file.write(
                            f"[INPUT]:\t{self.MANAGER.previous_input[1:]}\n[OUTPUT]:\t{self.MANAGER.previous_message}\n\n"
                        )
                else:
                    with open(self.logging_dialogues, "a") as log_file:
                        log_file.write(f"[{ROLE}]:\n\t\t\t{MSG}\n")
                    if ROLE.endswith("-input"):
                        print(f"[{ROLE}]:\n\t{MSG}\n\n")
                    else:
                        print(f"[{ROLE}-output]: \n\t{MSG}\n\n------------------------------------------------\n")
            else:
                print(
                    f"""
                ------------------------------------------------
                                BATCH START {self.id}
                ------------------------------------------------
                Prompt type:\t{SUMMARY[0]}
                Exp start:\t{SUMMARY[1]}
                Model:\t{SUMMARY[2]}
                Seed:\t{SUMMARY[3]}
                Board ID:\t{self.BOARD_ID}
                Boards: 
                    \tBOT:\t{SUMMARY[4]["BOT"]}
                    \tUSER:\t{SUMMARY[4]['USER']}
                    \tOPTIMAL:\t{SUMMARY[5]["OPTIMAL"]}
                ------------------------------------------------\n"""
                )

                with open(self.logging_dialogues, "a") as log_file:
                    log_file.write(
                        f"""
                ------------------------------------------------                   
                                BATCH START {self.id}
                ------------------------------------------------
                Prompt type:\t{SUMMARY[0]}
                Exp start:\t{SUMMARY[1]}
                Model:\t{SUMMARY[2]}
                Seed:\t{SUMMARY[3]}
                Board ID:\t{self.BOARD_ID}
                Boards: \t\tBOT:\t{SUMMARY[4]["BOT"]}
                        \t\tUSER:\t{SUMMARY[4]['USER']}
                        \t\tOPTIMAL:\t{SUMMARY[5]["OPTIMAL"]}
                ------------------------------------------------\n"""
                    )

                with open(self.logging_GSM, "a") as log_file:
                    log_file.write(
                        f"""
                ------------------------------------------------                   
                                BATCH START {self.id}
                ------------------------------------------------
                Prompt type:\t{SUMMARY[0]}
                Exp start:\t{SUMMARY[1]}
                Model:\t{SUMMARY[2]}
                Seed:\t{SUMMARY[3]}
                Board ID:\t{self.BOARD_ID}
                Boards: \t\tBOT:\t{SUMMARY[4]["BOT"]}
                        \t\tUSER:\t{SUMMARY[4]['USER']}
                        \t\tOPTIMAL:\t{SUMMARY[5]["OPTIMAL"]}
                ------------------------------------------------\n"""
                    )

        elif MODE == "eval":
            with open(self.logging_eval, "a") as log_file:
                log_file.write(
                    f"""
        ------------------------------------------------
                        EVALUATION BREAKDOWN {self.id}
        ------------------------------------------------
                               BASICS
        ------------------------------------------------                       
        Experiment start:\t{self.run_start}
        Prompt type:\t{self.prompt_type}
        Model:\t{self.model}
        Seed:\t{self.seed}
        Board ID:\t{self.BOARD_ID}
        Starting boards:
                \t\tBOT:\t{self.boards["BOT"]}
                \t\tUSER:\t{self.boards['USER']}
        ------------------------------------------------
                        FINAL PATHS
        ------------------------------------------------
        BOT:\t{self.solutions["BOT"]}
        USER:\t{self.solutions['USER']}
        OPTIMAL:\t{self.solutions["OPTIMAL"]}
        ------------------------------------------------
                        EVALUATION RESULTS
        ------------------------------------------------
        \tScore:\t{self.results["SCORE"]}
        \tIdentical:\t{self.results["IDENTICAL"]}
        \tOptimal:\t{self.results["OPTIMAL"]}
        \tAdequate:\t{self.results["ADEQUATE"]}
        \tEmpty-bot:\t{self.results["EMPTY-bot"]}
        \tEmpty-user:\t{self.results["EMPTY-user"]}
        ------------------------------------------------
"""
                )
        elif MODE == "eval-terminated":
            with open(self.logging_eval, "a") as log_file:
                log_file.write(
                    f"""
        ------------------------------------------------
                        EVALUATION BREAKDOWN {self.id}
        ------------------------------------------------
                               BASICS
        ------------------------------------------------                       
        Experiment start:\t{self.run_start}
        Prompt type:\t{self.prompt_type}
        Model:\t{self.model}
        Seed:\t{self.seed}
        Board ID:\t{self.BOARD_ID}
        Starting boards:
                \t\tBOT:\t{self.boards["BOT"]}
                \t\tUSER:\t{self.boards['USER']}
        ------------------------------------------------
                    FINAL PATHS -- TERMINATED
        ------------------------------------------------
        BOT:\t{self.solutions["BOT"]}
        USER:\t{self.solutions['USER']}
        OPTIMAL:\t{self.solutions["OPTIMAL"]}
        ------------------------------------------------"""
                )

    def parse_message(self, MESSAGE):
        """A function that uses regex to parse the given MESSAGE and extract flags (Thought, Action, Message).

        :param MESSAGE: str
        :return result: dict (key - flag (str); val - contents (str)); the extracted data
        """
        result = {}

        # regex to match the pattern [FLAG]: followed by content
        # capture everything after a flag until the next flag or the end of the string
        try:
            pattern = r"\[([^\]]+)\]:(.*?)(?=\[\w+\]|$)"
            matches = re.findall(pattern, MESSAGE, flags=re.DOTALL)

            if (
                not matches
            ):  # if matches is empty, raise an exception to trigger the except block (format issue, no doppelpunkt)
                raise Exception("No matches found with initial pattern")

            for flag, content in matches:
                result[flag.strip()] = content.strip()

        except:
            pattern = r"\[([^\]]+)\](.*?)(?=\[\w+\]|$)"
            matches = re.findall(pattern, MESSAGE, flags=re.DOTALL)

            for flag, content in matches:
                result[flag.strip()] = content.strip()

        return result

    def parse_actions(self, actions, ROLE="BOT"):
        
        pattern = r'end\((.*?)\)'
        matches = re.findall(pattern, actions)
        if matches:
            FINAL_PATH = [ast.literal_eval(match) for match in matches][0]
            self.solutions[ROLE] = FINAL_PATH
            self.end[ROLE] = True

        self.actions_history[ROLE].append(actions)

    def check_end(self):

        for key in self.actions_history.keys():
            for el in self.actions_history[key]:
                if el.startswith("end("):
                    self.end[key] = True

    def run(self, start, TURNS):
        
        # logging the basics into the dialogue file 
        self.user_proxy.update_message_history(start)

        while self.playing:
            # terminate the program in case the agents get stuck in a loop
            TURNS -= 1
            if TURNS == 0:
                break

            self.check_end()

            if self.end["USER"] and self.end["BOT"]:
                self.solution_verification()
                self.playing = False
                pass

            user_message = self.user_proxy.get_inference() # messages generated by the user proxy:
            self.log(MSG=user_message, ROLE="USER")  # log user message
            user_message_PARSED = self.parse_message(user_message)

            # GROUND STATE MANAGER --> update the BOT's "other state" (after user's turn)
            # if "Message" in user_message_PARSED.keys():
            try:

                gsm_output_raw = self.MANAGER.get_inference(user_message_PARSED["Message"], self.bot.other_user_WS, "LIGHT")
                gsm_output_parsed = self.parse_message(gsm_output_raw)
                self.log(ROLE="GSM")
                NWS = re.sub(
                    r"[^a-zA-Z0-9\s\[\]\(\)\"',]", "", gsm_output_parsed["NWS"].strip()
                )  # NWS = new world state

                self.bot.other_user_WS += ast.literal_eval(
                    NWS
                )
            except:
                pass

            try:
                self.parse_actions(user_message_PARSED["Action"], "USER")
            except:
                pass

            try:
                new_string = f"[World-state-own]: {self.boards["BOT"]}\n[World-state-user]: {self.bot.other_user_WS}\n[History]: {self.actions_history["BOT"]}\n[Observation]: {user_message_PARSED["Message"]}" # format input for bot
            except:
                new_string = f"[World-state-own]: {self.boards["BOT"]}\n[World-state-user]: {self.bot.other_user_WS}\n[History]: {self.actions_history["BOT"]}\n[Observation]: <USESR MESSAGE IN WRONG FORMAT>" # format input for bot
            
            self.log(MSG=new_string, ROLE="BOT-input")
            self.bot.update_message_history(new_string)

            if self.end["USER"] and self.end["BOT"]:
                self.solution_verification()
                self.playing = False
                break

            else:
                bot_message = self.bot.get_inference()
                self.log(MSG=bot_message, ROLE="BOT") # log bot message
                bot_message_PARSED = self.parse_message(bot_message) # extract bot actions

                # GROUND STATE MANAGER --> update the state based on message and old state
                # if "Message" in bot_message_PARSED.keys(): # if user message is properly formatted, extract and pass to GSM
                try:
                    gsm_output_raw = self.MANAGER.get_inference(bot_message_PARSED["Message"], self.user_proxy.other_user_WS, "GHOST")
                    gsm_output_parsed = self.parse_message(gsm_output_raw)
                    self.log(ROLE="GSM")
                    NWS = re.sub(
                        r"[^a-zA-Z0-9\s\[\]\(\)\"',]",
                        "",
                        gsm_output_parsed["NWS"].strip(),
                    )
                    self.user_proxy.other_user_WS += ast.literal_eval(
                        NWS
                    ) 
                # else continue without updating
                except:
                    pass

                try:
                    self.parse_actions(bot_message_PARSED["Action"], "BOT")                    
                except:
                    pass

                try:
                    new_string = f"[World-state-own]: {self.boards["USER"]}\n[World-state-user]: {self.user_proxy.other_user_WS}\n[History]: {self.actions_history["USER"]}\n[Observation]: {bot_message_PARSED["Message"]}" # format input for bot
                except:
                    new_string = f"[World-state-own]: {self.boards["USER"]}\n[World-state-user]: {self.user_proxy.other_user_WS}\n[History]: {self.actions_history["USER"]}\n[Observation]: <USESR MESSAGE IN WRONG FORMAT>" # format input for bot
                
                self.user_proxy.update_message_history(new_string)
                self.log(MSG=new_string, ROLE="USER-input")

                if self.end["USER"] and self.end["BOT"]:
                    self.solution_verification()
                    self.playing = False
                    break

        # Log the eval results to a separate eval file
                # Log the eval results to a separate eval file
        if not (self.end["USER"] and self.end["BOT"]):
            self.log(MODE='eval-terminated')
        else:
            self.log(MODE="eval")

class BotInstance:
     
    def __init__(self, BASE_PROMPT:str, MODEL:str, SEED:int, MAXTOKENS:int, BOARD:list):
        ''' 
        A class for the agents playing the game;

        :param BASE_PROMPT: str; the starting system prompt describing the task + example
        :param MODEL: str; OpenAI model
        :param SEED: int;
        :param MAXTOKENS: int;
        :param BOARD: list; the agent's graph. format [("edge1", "edge2", intval), ...]
        '''
        self.msg_history = [{"role":"system", "content":BASE_PROMPT}]
        self.model = MODEL # gpt-4o-2024-08-06
        self.seed = SEED
        self.MAXTOKENS = MAXTOKENS
        self.other_user_WS = [] # the other user's world state
        self.BOARD = BOARD # own board
        self.total_board = list(BOARD) # own board + what is known from the user's board
        self.IBP = [] # "intermediate best path" 

    def inference(self): 
        ''' A function that calls the OpenAI API using the previously set parameters

        :return output: str; model output
        '''
        client = OpenAI(api_key=OPENAI_API_KEY)
        completion = client.chat.completions.create(
        model=self.model,
        messages=self.msg_history,
        max_tokens=self.MAXTOKENS,
        temperature=1,
        seed=self.seed
        )
        output = completion.choices[0].message.content        
        return output

    def get_inference(self):

        raw_output = self.inference()
        self.msg_history.append({"role":"assistant", "content":raw_output})
        self.recent_message = raw_output

        return raw_output
    
    def update_message_history(self,new_message):
        self.msg_history.append({"role":"user", "content":new_message})
                
class GroundStateManager:
    def __init__(self, BASE_PROMPT: str, MODEL: str, SEED: int, MAXTOKENS: int):
        """
        A class for the LLM-based Ground State Manager (GSM), whose main job is to extract new information about the graph of "the other player".

        :param BASE_PROMPT: str; the system prompt - task explanation + example.
        :param MODEL: str; the OpenAI model to be called
        :param SEED: int;
        :param MAXTOKENS:int;
        """
        self.msg_history = [{"role": "system", "content": BASE_PROMPT}]
        self.model = MODEL  # "gpt-4o-2024-08-06"
        self.seed = SEED
        self.MAXTOKENS = MAXTOKENS
        self.previous_input = None  # the last recorded input str; for logging purposes

    def inference(self, input: list):
        """A function that calls the OpenAI API using the previously set parameters

        :return output: str; model output
        """
        client = OpenAI(api_key=OPENAI_API_KEY)
        completion = client.chat.completions.create(
            model=self.model,
            messages=input,
            max_tokens=self.MAXTOKENS,
            temperature=1,
            seed=self.seed,
        )
        output = completion.choices[0].message.content
        return output

    def make_input(self, message: str, old_ws: list, world: str):
        """A function that generates the input to be passed to the LLM. Does not store previous messages, just appends the newest inquiry to the base prompt.
        :param message: str;
        :param old_ws: list; "old world state" - the parts of the other player's graph that have been found out
        :return input: list(dict); the input list of messages to be passed to the LLM
        """
        input_string = f"[Message]: {message}\n[OWS]: {old_ws}\n[World]:{world}"
        formatted_input = [{"role": "user", "content": input_string}]
        input = self.msg_history + formatted_input
        return input

    def get_inference(self, MESSAGE: str, OWS: list, WORLD: str):
        """A function that organizes the LLM API call and stores data where necessary.

        :param MESSAGE: str;
        :param OWS: list; "old world state", a.k.a. the parts of the other player's graph that have been found out

        :return raw_output: str; the complete output of the LLM. format: [Thought]: ... \n [NWS]: ...\n
        """
        input = self.make_input(MESSAGE, OWS, WORLD)
        raw_output = self.inference(input)
        self.previous_input = input
        self.previous_message = raw_output

        return raw_output
    

def main():

    NODES = 6
    BOARDS_PATH = f"boards_{NODES}.json"
    n = 25
    version = "full-v4-new-actions-redo"
    setup = f"{NODES}nodes"

    for seed in [1011, 143, 9999, 8060]:
    # seed = 1011 # 9999 1234 8060
        run_start = datetime.now()
        path = f"logs/{version}/{setup}"
        if not os.path.exists(path):
            os.makedirs(path)
        
        logging_didalogues = f"{path}/{seed}-{run_start}-dialogues.txt"
        logging_eval = f"{path}/{seed}-{run_start}-eval.txt"
        logging_GSM = f"{path}/{seed}-{run_start}-GSM.txt"

        with open(BOARDS_PATH, "r") as file:
            boards = json.load(file)
        
        for i in range(n):
        # send a random board from json file
            ID = f"{seed}-{i}"
            board_index = str(randint(1,6))
            board = boards[board_index]
            game = GAME(NODES, board, seed, logging_didalogues, logging_eval, logging_GSM, board_index, ID) # start a game instance
            start = f"[World-state-own]: {game.boards["USER"]}\n[World-state-user]: {game.user_proxy.other_user_WS}\n[History]:{game.actions_history["USER"]}\n[Observation]: <START>" # starting prompt for USER agent (hard-coded to go first)
            game.log(
            SUMMARY=[
                game.prompt_type,
                game.run_start,
                game.model,
                game.seed,
                game.boards,
                game.solutions,
            ]
        )
            game.log(MSG=start, ROLE="USER-input")
            game.run(start=start, TURNS=16) 


if __name__ == "__main__":
    main()