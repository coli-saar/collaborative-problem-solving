import ast
import json
import os
import re
from datetime import datetime
from itertools import combinations
from random import randint

from openai import OpenAI

import supplementary.ilp_solver as ilp_solver
import supplementary.tsp_utils as tsp_utils
from supplementary.config import *
from AGENTS.prompts_problem_solving import *


class GAME:
    def __init__(
        self,
        N: int,
        BOARD: dict,
        SEED: int,
        LOG_DIAL: str,
        LOG_EVAL: str,
        LOG_GSM: str,
        BOARD_ID: int,
        ID: int,
    ):
        """The GAME-governing class

        :param N: int; number of nodes
        :param BOARD: dict; dict contianing the boards for both agents, indexed under roles (BOT, USER).
        :param SEED: int; batch marker; same for both agents
        :param LOG_DIAL: str; path to dialogue log file
        :param LOG_EVAL: str; path to eval log file
        :param LOG_GSM: str;  path to GroundStateManager (GSM) log file
        :param BOARD_ID: int; the ID of the board (used for logging)
        :param ID: int; the ID of the game within the batch (used for logging)
        """

        # parameters for naming convention
        self.run_start = datetime.now()
        self.id = ID
        self.prompt_type = "GSM, constrained action space, remaining rooms, IBP (from subpath)"

        self.N = N  # number of nodes
        self.other_user = {
            "BOT": "USER",
            "USER": "BOT",
        }  # structure for efficient indexing of the "other" user, when given the current user as key

        self.rooms = {
            "BOT": ["L", "E", "K", "B"],
            "USER": ["L", "E", "K", "B"],
        }  # list of available rooms (default: 4-nodes)

        # add other rooms depending on the number of nodes
        if self.N >= 5:
            self.rooms["BOT"].append("C")
            self.rooms["USER"].append("C")
        if self.N == 6:
            self.rooms["BOT"].append("A")
            self.rooms["USER"].append("A")

        # Logging files
        self.logging_dialogues = LOG_DIAL  # logging file containing all dialogues
        self.logging_GSM = LOG_GSM  # logging file containing all ground state manager outputs
        self.logging_eval = LOG_EVAL  # logging file containing all evaluation info

        # Graph contents - read from json outside of class
        self.boards = {
            "BOT": BOARD["BOT"],
            "USER": BOARD["USER"],
        }  # the boards given to the players
        self.solutions = {
            "BOT": [],
            "USER": [],
            "OPTIMAL": BOARD["OPTIMAL"],
        }  # storing the produced solutions for evaluation; OPTIMAL is the path that returns the most joint coins
        self.BOARD_ID = BOARD_ID

        # Flags
        self.playing = True  # True = the game is ongoing

        # DATA STRUCTURES
        self.actions_history = {
            "BOT": [],
            "USER": [],
        }  # list of  not used in this version
        self.agreements_history = {"BOT": [], "USER": []}  # might not be used, TBD
        self.end = {
            "BOT": False,
            "USER": False,
        }  # dict for storing whether an "end" actioin was generated by each

        # Agent params
        self.seed = SEED
        self.model = "gpt-4o-2024-08-06"
        self.bot_params = self.get_params("BOT")
        self.user_params = self.get_params("USER")

        # Players
        self.bot = BotInstance(
            BASE_PROMPT=GHOST_prompt(self.bot_params, self.N),
            MODEL=self.model,
            SEED=self.seed,
            MAXTOKENS=1200,
            BOARD=BOARD["BOT"],
        )  # bot agent
        self.bot.intermediate_best_path()  # calculate an initial best path

        self.user_proxy = BotInstance(
            BASE_PROMPT=USER_LIGHT_prompt(self.user_params, self.N),
            MODEL=self.model,
            SEED=self.seed,
            MAXTOKENS=1200,
            BOARD=BOARD["USER"],
        )  # user agent
        self.user_proxy.intermediate_best_path()  # calculate an initial best path

        # Ground State Manager (GSM) - extracts information from message
        self.MANAGER = GroundStateManager(
            BASE_PROMPT=get_current_ws(self.N),
            MODEL=self.model,
            SEED=self.seed,
            MAXTOKENS=600,
        )

        self.PLAYERS = {"BOT":self.bot, "USER":self.user_proxy}

        # Eval flags:
        # identical - are the two agents' solutions identical?
        # adequate - is the solution of proper length? (may not be optimal)
        # optimal - is the given solution optimal?
        # empty-{bot|user} - is the {bot|user}'s submission empty
        self.results = {
            "IDENTICAL": False,
            "ADEQUATE": False,
            "OPTIMAL": False,
            "EMPTY-bot": False,
            "EMPTY-user": False,
            "SCORE": 0,
            "FINAL-IDENTICAL":{"BOT":False, "USER":False}
        }

    def get_params(self, player):
        """A function for unpacking the parameters from hard-coded boards to be passed to the respective agent.

        :param player: str; BOT or USER
        :return params: dict; {"node1node2": val, ...}
        """

        unique_nodes = set(node for pair in self.boards[player] for node in pair[:2])
        pairs = combinations(
            unique_nodes, 2
        )  # generate all possible pairs using combinations

        # create dictionary with keys like "LB", "LE", etc., and lookup values in entity data
        params = {
            f"{x}{y}": next(
                (v for (p1, p2, v) in self.boards[player] if {p1, p2} == {x, y}), None
            )
            for x, y in pairs
        }
        return params

    def get_score(self):
        """A function for calculating the score of the (identical) path the players agreed upon by using their given boards. Updates the self.results["SCORE"] variable"""

        score = 0
        path = self.solutions[
            "BOT"
        ]  # the solution is identical, using BOT path as a proxy
        pairs = [(path[i], path[i + 1]) for i in range(len(path) - 1)]

        sum_board = [
            (a, b, el1 + el2)
            for [a, b, el1] in self.boards["BOT"]
            for [a2, b2, el2] in self.boards["USER"]
            if a == a2 and b == b2
        ]

        for pair in pairs:
            score += [
                value[2]
                for value in sum_board
                if (pair[0] == value[0] and pair[1] == value[1])
                or (pair[0] == value[1] and pair[1] == value[0])
            ][0]

        self.results["SCORE"] = score

    def solution_verification(self):
        """A function for evaluating the models' performance - checks if the generated solutions are:
        - identical
        - adequate
        - optimal
        - empty
        """
        # if there is an empty list in the values, determine which one
        if len(self.solutions["BOT"]) == 0:
            self.results["EMPTY-bot"] = True
        if len(self.solutions["USER"]) == 0:
            self.results["EMPTY-user"] = True

        # if both players submit a solution (i.e. no empty list in the values)
        if all(self.solutions[key] for key in self.solutions):
            if (
                self.solutions["BOT"] == self.solutions["USER"]
            ):  # if both key dictionaries are the same
                self.results["IDENTICAL"] = True  # set identical to true
                self.get_score()
                if len(self.solutions["BOT"]) == (self.N + 1):
                    self.results["ADEQUATE"] = True

                if self.results["SCORE"] == self.solutions["OPTIMAL"][-1]:
                    # if the calculated score is the same as the best achievable path
                    self.results["OPTIMAL"] = True

    def log(self, MODE="dialogue", MSG="Default", ROLE="BOT", SUMMARY=None):
        """Logging function;

        :param  MODE: str; default: dialogue; distinguishes the kind of
        :param MSG: str; the message being logged, only needed for "dialogue" MODE
        :param ROLE: str; the message sender; options: BOT, USER, GSM
        :param SUMMARY: list of len 6; experiment instance metadata -
            [
                prompt type,
                start time / date,
                model,
                seed,
                board dict (keys: "BOT", 'USER'),
                optimal path(s)
            ]
        """
        if MODE == "dialogue":
            if SUMMARY == None:
                if ROLE == "GSM":  # GSM
                    with open(self.logging_GSM, "a") as log_file:
                        log_file.write(
                            f"[INPUT]:\t{self.MANAGER.previous_input[1:]}\n[OUTPUT]:\t{self.MANAGER.previous_message}\n\n"
                        )
                else:
                    with open(self.logging_dialogues, "a") as log_file:
                        log_file.write(f"[{ROLE}]:\n\t\t\t{MSG}\n")
                    if ROLE.endswith("-input"):
                        print(f"[{ROLE}]:\n\t{MSG}\n\n")
                    else:
                        print(f"[{ROLE}-output]: \n\t{MSG}\n\n------------------------------------------------\n")
            else:
                print(
                    f"""
                ------------------------------------------------
                                BATCH START {self.id}
                ------------------------------------------------
                Prompt type:\t{SUMMARY[0]}
                Exp start:\t{SUMMARY[1]}
                Model:\t{SUMMARY[2]}
                Seed:\t{SUMMARY[3]}
                Board ID:\t{self.BOARD_ID}
                Boards: 
                    \tBOT:\t{SUMMARY[4]["BOT"]}
                    \tUSER:\t{SUMMARY[4]['USER']}
                    \tOPTIMAL:\t{SUMMARY[5]["OPTIMAL"]}
                ------------------------------------------------\n"""
                )

                with open(self.logging_dialogues, "a") as log_file:
                    log_file.write(
                        f"""
                ------------------------------------------------                   
                                BATCH START {self.id}
                ------------------------------------------------
                Prompt type:\t{SUMMARY[0]}
                Exp start:\t{SUMMARY[1]}
                Model:\t{SUMMARY[2]}
                Seed:\t{SUMMARY[3]}
                Board ID:\t{self.BOARD_ID}
                Boards: \t\tBOT:\t{SUMMARY[4]["BOT"]}
                        \t\tUSER:\t{SUMMARY[4]['USER']}
                        \t\tOPTIMAL:\t{SUMMARY[5]["OPTIMAL"]}
                ------------------------------------------------\n"""
                    )

                with open(self.logging_GSM, "a") as log_file:
                    log_file.write(
                        f"""
                ------------------------------------------------                   
                                BATCH START {self.id}
                ------------------------------------------------
                Prompt type:\t{SUMMARY[0]}
                Exp start:\t{SUMMARY[1]}
                Model:\t{SUMMARY[2]}
                Seed:\t{SUMMARY[3]}
                Board ID:\t{self.BOARD_ID}
                Boards: \t\tBOT:\t{SUMMARY[4]["BOT"]}
                        \t\tUSER:\t{SUMMARY[4]['USER']}
                        \t\tOPTIMAL:\t{SUMMARY[5]["OPTIMAL"]}
                ------------------------------------------------\n"""
                    )

        elif MODE == "eval":
            with open(self.logging_eval, "a") as log_file:
                log_file.write(
                    f"""
        ------------------------------------------------
                        EVALUATION BREAKDOWN {self.id}
        ------------------------------------------------
                               BASICS
        ------------------------------------------------                       
        Experiment start:\t{self.run_start}
        Prompt type:\t{self.prompt_type}
        Model:\t{self.model}
        Seed:\t{self.seed}
        Board ID:\t{self.BOARD_ID}
        Starting boards:
                \t\tBOT:\t{self.boards["BOT"]}
                \t\tUSER:\t{self.boards['USER']}
        ------------------------------------------------
                        FINAL PATHS
        ------------------------------------------------
        BOT:\t{self.solutions["BOT"]}
        USER:\t{self.solutions['USER']}
        OPTIMAL:\t{self.solutions["OPTIMAL"]}
        ------------------------------------------------
                        EVALUATION RESULTS
        ------------------------------------------------
        \tScore:\t{self.results["SCORE"]}
        \tIdentical:\t{self.results["IDENTICAL"]}
        \tOptimal:\t{self.results["OPTIMAL"]}
        \tAdequate:\t{self.results["ADEQUATE"]}
        \tEmpty-bot:\t{self.results["EMPTY-bot"]}
        \tEmpty-user:\t{self.results["EMPTY-user"]}
        \tVisited=final-BOT:\t{self.results["FINAL-IDENTICAL"]["BOT"]}
        \tVisited=final-USER:\t{self.results["FINAL-IDENTICAL"]["USER"]}
        ------------------------------------------------
"""
                )
        elif MODE == "eval-terminated":
            with open(self.logging_eval, "a") as log_file:
                log_file.write(
                    f"""
        ------------------------------------------------
                        EVALUATION BREAKDOWN {self.id}
        ------------------------------------------------
                               BASICS
        ------------------------------------------------                       
        Experiment start:\t{self.run_start}
        Prompt type:\t{self.prompt_type}
        Model:\t{self.model}
        Seed:\t{self.seed}
        Board ID:\t{self.BOARD_ID}
        Starting boards:
                \t\tBOT:\t{self.boards["BOT"]}
                \t\tUSER:\t{self.boards['USER']}
        ------------------------------------------------
                    FINAL PATHS -- TERMINATED
        ------------------------------------------------
        BOT:\t{self.solutions["BOT"]}
        USER:\t{self.solutions['USER']}
        OPTIMAL:\t{self.solutions["OPTIMAL"]}
        ------------------------------------------------"""
                )

    def parse_message(self, MESSAGE):
        """A function that uses regex to parse the given MESSAGE and extract flags (Thought, Action, Message).

        :param MESSAGE: str
        :return result: dict (key - flag (str); val - contents (str)); the extracted data
        """
        result = {}

        # regex to match the pattern [FLAG]: followed by content
        # capture everything after a flag until the next flag or the end of the string
        try:
            pattern = r"\[([^\]]+)\]:(.*?)(?=\[\w+\]|$)"
            matches = re.findall(pattern, MESSAGE, flags=re.DOTALL)

            if (
                not matches
            ):  # if matches is empty, raise an exception to trigger the except block (format issue, no doppelpunkt)
                raise Exception("No matches found with initial pattern")

            for flag, content in matches:
                result[flag.strip()] = content.strip()

        except:
            pattern = r"\[([^\]]+)\](.*?)(?=\[\w+\]|$)"
            matches = re.findall(pattern, MESSAGE, flags=re.DOTALL)

            for flag, content in matches:
                result[flag.strip()] = content.strip()

        return result

    def parse_actions(self, actions, ROLE="BOT"):

        list_of_actions = re.findall(
            r"\w+\-*\w*\(.*?\)", actions
        )  # separates the generated actions into a list
        path_pattern = r"\((.*?)\)"
        for action in list_of_actions:
            action_contents = re.findall(path_pattern, action)[
                0
            ]  # str, just the param, e.g. "['C', 'K']" or "['A', 'B', 'C', 'D', 'E']" or "K"
            if action.startswith("end"):  # end action

                FINAL_PATH = ast.literal_eval(action_contents)
                self.solutions[ROLE] = FINAL_PATH
                self.end[ROLE] = True
                if FINAL_PATH == self.PLAYERS[ROLE].visited:
                    self.results["FINAL-IDENTICAL"][ROLE] = True

            elif action.startswith("ask") or action.startswith("inform"):
                # add to actions_history
                self.actions_history[ROLE].append(action)

            elif (
                action.startswith("reject")
                or action.startswith("visit")
                or action.startswith("agree")
            ):

                if (
                    action not in self.agreements_history[ROLE]
                ):  # one suggestion and one final agreement can only be done once
                    # add the original action (same for both agents)

                    if action.startswith("visit"):
                        # update the list of rooms to exclude the room that has been labeled as "visited"
                        index_of_visited = self.rooms[ROLE].index(
                            re.search(r"[a-zA-Z]", ast.literal_eval(action_contents))
                            .group()
                            .upper()
                        )  # eliminate the quotation marks
                        self.rooms[ROLE].pop(index_of_visited)
                        self.PLAYERS[ROLE].visited.append(ast.literal_eval(action_contents))

                    self.agreements_history[ROLE].append(action)

    def run(self, start, TURNS):
        """The function for starting the 2-agent game. USER agent goes first

        :param start: str; initial prompt for the agent that goes first (USER)
        :param TURNS: int; n+1 many turns to run (default: 11)
        """

        # logging the basics into the dialogue file
        self.user_proxy.update_message_history(start)

        while self.playing:
            # terminate the program in case the agents get stuck in a loop
            TURNS -= 1
            if TURNS == 0:
                break

            if self.end["USER"] and self.end["BOT"]:
                self.solution_verification()
                self.playing = False
                break

            #################### USER BLOCK ####################
            user_message = (
                self.user_proxy.get_inference()
            )  # messages generated by the user proxy
            self.log(MSG=user_message, ROLE="USER")  # log user message
            user_message_PARSED = self.parse_message(
                user_message
            )  # separate [Thought] [Action] and [Message]
            try:
                self.parse_actions(user_message_PARSED["Action"], "USER")
            except:
                pass

            # GROUND STATE MANAGER BLOCK: update the BOT's "other state" (after USER's turn)
            try:
                gsm_output_raw = self.MANAGER.get_inference(
                    user_message_PARSED["Message"], self.bot.other_user_WS, self.user_proxy.visited[-1], "LIGHT"
                )
                gsm_output_parsed = self.parse_message(gsm_output_raw)
                self.log(ROLE="GSM")
                NWS = re.sub(
                    r"[^a-zA-Z0-9\s\[\]\(\)\"',]", "", gsm_output_parsed["NWS"].strip()
                )  # NWS = new world state

                self.bot.other_user_WS += ast.literal_eval(
                    NWS
                )  # update in bot's history
                if len(ast.literal_eval(NWS)) > 0:
                    self.bot.update_total_board(ast.literal_eval(NWS))
                    
            except:  # formatting issue
                pass

            self.bot.intermediate_best_path()  # update the IBP based on the new info

            try:
                new_string = f"[World-state-own]: {self.boards['BOT']}\n[World-state-user]: {self.bot.other_user_WS}\n[Remaining]: {self.rooms["BOT"]}\n[Visited]: {self.bot.visited}\n[IBP]: {self.bot.IBP}\n[Observation]: {user_message_PARSED['Message']}"

            except:  # if there is an error is user message formatting (cannot access [user_message_PARSED['Message']])
                new_string = f"[World-state-own]: {self.boards['BOT']}\n[World-state-user]: {self.bot.other_user_WS}\n[Remaining]: {self.rooms["BOT"]}\n[Visited]: {self.bot.visited}\n[IBP]: {self.bot.IBP}\n[Observation]: <USER MESSAGE IN WRONG FORMAT>"

            print(f'INPUT - BOT: {new_string}\n')
            self.log(MSG=new_string, ROLE="BOT-input")
            self.bot.update_message_history(
                new_string
            )  # add new input (based on the USER's output) to BOT's msg history

            if self.end["USER"] and self.end["BOT"]:
                self.solution_verification()
                self.playing = False
                continue

            #################### BOT BLOCK ####################
            else:
                bot_message = self.bot.get_inference()
                self.log(MSG=bot_message, ROLE="BOT")  # log bot message
                bot_message_PARSED = self.parse_message(
                    bot_message
                )  # extract bot actions

                try:
                    self.parse_actions(bot_message_PARSED["Action"], "BOT")
                except:
                    pass

                # GROUND STATE MANAGER block: update the state based on message and old state
                try:
                    gsm_output_raw = self.MANAGER.get_inference(
                        bot_message_PARSED["Message"], self.user_proxy.other_user_WS, self.bot.visited[-1], "GHOST"
                    )
                    gsm_output_parsed = self.parse_message(gsm_output_raw)
                    self.log(ROLE="GSM")
                    NWS = re.sub(
                        r"[^a-zA-Z0-9\s\[\]\(\)\"',]",
                        "",
                        gsm_output_parsed["NWS"].strip(),
                    )
                    self.user_proxy.other_user_WS += ast.literal_eval(
                        NWS
                    )  # update in user proxy's history
                    if len(ast.literal_eval(NWS)) > 0:
                        self.user_proxy.update_total_board(
                            ast.literal_eval(NWS)
                        )  # update user proxy's total_board
            
                    # else continue without updating
                except:  # formatting issue in parsing GSM's message OR extracting NWS
                    pass
                
                self.user_proxy.intermediate_best_path()  # update the IBP based on the new info

                try:
                    new_string = f"[World-state-own]: {self.boards['USER']}\n[World-state-user]: {self.user_proxy.other_user_WS}\n[Remaining]: {self.rooms["USER"]}\n[Visited]: {self.user_proxy.visited}\n[IBP]: {self.user_proxy.IBP}\n[Observation]: {bot_message_PARSED['Message']}"
                except:
                    new_string = f"[World-state-own]: {self.boards['USER']}\n[World-state-user]: {self.user_proxy.other_user_WS}\n[Remaining]: {self.rooms["USER"]}\n[Visited]: {self.user_proxy.visited}\n[IBP]: {self.user_proxy.IBP}\n[Observation]: <USER MESSAGE IN WRONG FORMAT>"

                self.user_proxy.update_message_history(new_string)
                print(f'INPUT - USER: {new_string}\n')
                self.log(MSG=new_string, ROLE="USER-input")
                if self.end["USER"] and self.end["BOT"]:
                    self.solution_verification()
                    self.playing = False
                    break

        # Log the eval results to a separate eval file
        if not (self.end["USER"] and self.end["BOT"]):
            self.log(MODE="eval-terminated")
        else:
            self.log(MODE="eval")


class BotInstance:

    def __init__(
        self, BASE_PROMPT: str, MODEL: str, SEED: int, MAXTOKENS: int, BOARD: list
    ):
        """
        A class for the agents playing the game;

        :param BASE_PROMPT: str; the starting system prompt describing the task + example
        :param MODEL: str; OpenAI model
        :param SEED: int;
        :param MAXTOKENS: int;
        :param BOARD: list; the agent's graph. format [("node1", "node2", intval), ...]
        """
        self.msg_history = [{"role": "system", "content": BASE_PROMPT}]
        self.model = MODEL  # gpt-4o-2024-08-06
        self.seed = SEED
        self.MAXTOKENS = MAXTOKENS
        self.other_user_WS = []  # the other user's world state
        self.BOARD = BOARD  # own board
        self.total_board = list(
            BOARD
        )  # own board + what is known from the user's board
        self.IBP = []  # "intermediate best path"
        self.IBC = 0  # "intermediate best coins"
        self.visited = ["L"] # list of rooms the users have agreed to visit 

    def inference(self):
        """A function that calls the OpenAI API using the previously set parameters

        :return output: str; model output
        """
        client = OpenAI(api_key=OPENAI_API_KEY)
        completion = client.chat.completions.create(
            model=self.model,
            messages=self.msg_history,
            max_tokens=self.MAXTOKENS,
            temperature=1,
            seed=self.seed,
        )
        output = completion.choices[0].message.content
        return output

    def get_inference(self):
        """A function organizing the LLM API call and storing the output where needed.

        :return raw_output: str; the model's output of format: [Thouoght]: ...\n[Action]:...\n[Message]:...
        """

        raw_output = self.inference()
        self.msg_history.append({"role": "assistant", "content": raw_output})
        return raw_output

    def update_message_history(self, new_message: str):
        """A function that updates the internal message history of the agent; only called with the other agent's input (role fixed to "user").
        :param new_message: str; the message to be appended
        """
        self.msg_history.append({"role": "user", "content": new_message})

    def update_total_board(self, addition: list):
        """
        A function that iteratively updates a complete internal board with new information from the user. When the user gives info about an edge, the new value gets added to the agent's own value of the same edge. Other (known) edges currently +0.

        :param addition: list; format [("node1", "node2", int-value), ...]
        """
        for el in addition:
            right_el = [
                element
                for element in self.total_board
                if element[0] == el[0] and element[1] == el[1]
            ][0]
            # right_el_idx = self.total_board.index(right_el)
            self.total_board.remove(right_el)
            self.total_board.append(
                tuple([right_el[0], right_el[1], int(el[2]) + int(right_el[2])])
            )  # (str, str, int)

    def intermediate_best_path(self, partial_path=["L"]) -> list[str]:
        """A function that calculates the best path for the agent's graph. The path is calculated based on the partial path (default: ["L"]) and the agent's total board.

        :param partial_path: list[str]; the partial path to be used as a starting point
        :return best_tour: list[str]; the calculated best path
        """

        g = tsp_utils.board_to_graph(self.total_board)
        tsp_utils.validate_graph(g)
        pp = self.visited if self.visited[-1] != "L" or len(self.visited) == 1 else self.visited[:-1]
        self.IBP, self.IBC = ilp_solver.solve(g, pp) # use self.visited as partial path
        self.IBP.append("L")
        return self.IBP


class GroundStateManager:
    def __init__(self, BASE_PROMPT: str, MODEL: str, SEED: int, MAXTOKENS: int):
        """
        A class for the LLM-based Ground State Manager (GSM), whose main job is to extract new information about the graph of "the other player".

        :param BASE_PROMPT: str; the system prompt - task explanation + example.
        :param MODEL: str; the OpenAI model to be called
        :param SEED: int;
        :param MAXTOKENS:int;
        """
        self.msg_history = [{"role": "system", "content": BASE_PROMPT}]
        self.model = MODEL  # "gpt-4o-2024-08-06"
        self.seed = SEED
        self.MAXTOKENS = MAXTOKENS
        self.previous_input = None  # the last recorded input str; for logging purposes

    def inference(self, input: list):
        """A function that calls the OpenAI API using the previously set parameters

        :return output: str; model output
        """
        client = OpenAI(api_key=OPENAI_API_KEY)
        completion = client.chat.completions.create(
            model=self.model,
            messages=input,
            max_tokens=self.MAXTOKENS,
            temperature=1,
            seed=self.seed,
        )
        output = completion.choices[0].message.content
        return output

    def make_input(self, message: str, old_ws: list, loc: str, world: str):
        """A function that generates the input to be passed to the LLM. Does not store previous messages, just appends the newest inquiry to the base prompt.
        :param message: str;
        :param old_ws: list; "old world state" - the parts of the other player's graph that have been found out
        :return input: list(dict); the input list of messages to be passed to the LLM
        """
        input_string = f"[Message]: {message}\n[OWS]: {old_ws}\n[Loc]: {loc}\n[World]:{world}"
        formatted_input = [{"role": "user", "content": input_string}]
        input = self.msg_history + formatted_input
        return input

    def get_inference(self, MESSAGE: str, OWS: list, LOC: str, WORLD: str):
        """A function that organizes the LLM API call and stores data where necessary.

        :param MESSAGE: str;
        :param OWS: list; "old world state", a.k.a. the parts of the other player's graph that have been found out

        :return raw_output: str; the complete output of the LLM. format: [Thought]: ... \n [NWS]: ...\n
        """
        input = self.make_input(MESSAGE, OWS, LOC, WORLD)
        raw_output = self.inference(input)
        self.previous_input = input
        self.previous_message = raw_output

        return raw_output


def main():
    """A function controling the flow of the experiment; includes meta-params, such as how many games are played per batch, seeds,"""

    NODES = 6  # CHANGE!
    BOARDS_PATH = f"boards/boards_{NODES}.json"
    n = 25  # how many games are played per batch
    version = "v14"  # CHANGE
    setup = f"{NODES}nodes"

    for seed in [1011, 143, 9999, 8060]:  # 1 seed = 1 batch
        run_start = datetime.now()
        path = f"logs/{version}/{setup}"
        if not os.path.exists(path):
            os.makedirs(path)

        logging_didalogues = f"{path}/{seed}-{run_start}-dialogues.txt"
        logging_eval = f"{path}/{seed}-{run_start}-eval.txt"
        logging_GSM = f"{path}/{seed}-{run_start}-GSM.txt"

        with open(BOARDS_PATH, "r") as file:
            boards = json.load(file)

        for i in range(n):
            # send a random board from json file
            ID = f"{seed}-{i}"
            board_index = str(randint(1, 6))
            board = boards[board_index]
            game = GAME(
                NODES,
                board,
                seed,
                logging_didalogues,
                logging_eval,
                logging_GSM,
                board_index,
                ID,
            )  # start a game instance
            start = f"[World-state-own]: {game.boards['USER']}\n[World-state-user]: {game.user_proxy.other_user_WS}\n[Remaining]: {game.rooms["USER"]}\n[Visited]: {game.user_proxy.visited}\n[IBP]: {game.user_proxy.IBP}\n[Observation]: <START>"  # starting prompt for USER agent (hard-coded to go first)
            game.log(
            SUMMARY=[
                game.prompt_type,
                game.run_start,
                game.model,
                game.seed,
                game.boards,
                game.solutions,
            ]
        )
            game.log(MSG=start, ROLE="USER-input")
            game.run(start=start, TURNS=16)


if __name__ == "__main__":
    main()
